{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Tutorial Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (StructField, \n",
    "                               StructType,\n",
    "                               StringType, \n",
    "                               IntegerType,\n",
    "                               FloatType,\n",
    "                               DateType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Schema and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticker: string (nullable = true)\n",
      " |-- open: float (nullable = true)\n",
      " |-- close: float (nullable = true)\n",
      " |-- adj_close: float (nullable = true)\n",
      " |-- low: float (nullable = true)\n",
      " |-- high: float (nullable = true)\n",
      " |-- volume: float (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_schema = [\n",
    "    StructField(\"ticker\", StringType(), True),\n",
    "    StructField(\"open\", FloatType()),\n",
    "    StructField(\"close\", FloatType()),\n",
    "    StructField(\"adj_close\", FloatType()),\n",
    "    StructField(\"low\", FloatType()),\n",
    "    StructField(\"high\", FloatType()),\n",
    "    StructField(\"volume\", FloatType()),\n",
    "    StructField(\"date\", DateType())\n",
    "]\n",
    "\n",
    "final_struct = StructType(fields=data_schema)\n",
    "\n",
    "data_frame = spark.read.csv(\"historical_stock_prices.csv\", schema=final_struct)\n",
    "data_frame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(symbol=None, opening_price=None, closing_price=None, adj_close=None, lowest_price=None, highest_price=None, volume=None, date=None, volume_in_millions=None),\n",
       " Row(symbol='AHH', opening_price=11.5, closing_price=11.579999923706055, adj_close=8.493154525756836, lowest_price=11.25, highest_price=11.680000305175781, volume=4633900.0, date=datetime.date(2013, 5, 8), volume_in_millions=4.6339)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame.withColumnRenamed(\"ticker\", \"symbol\")\n",
    "data_frame = data_frame.withColumnRenamed(\"open\", \"opening_price\")\n",
    "data_frame = data_frame.withColumnRenamed(\"close\", \"closing_price\")\n",
    "data_frame = data_frame.withColumnRenamed(\"low\", \"lowest_price\")\n",
    "data_frame = data_frame.withColumnRenamed(\"high\", \"highest_price\")\n",
    "\n",
    "data_frame = data_frame.withColumn(\"volume_in_millions\", data_frame[\"volume\"] / 1000000)\n",
    "\n",
    "data_frame.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.createOrReplaceTempView(\"stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-------------+-----------+------------+-------------+-----------+----------+------------------+\n",
      "|symbol|opening_price|closing_price|  adj_close|lowest_price|highest_price|     volume|      date|volume_in_millions|\n",
      "+------+-------------+-------------+-----------+------------+-------------+-----------+----------+------------------+\n",
      "|  MSFT|  0.088541664|  0.097222224| 0.07085974| 0.088541664|    0.1015625|1.0317888E9|1986-03-13|         1031.7888|\n",
      "|  MSFT|  0.097222224|   0.10069445|  0.0733905| 0.097222224|   0.10243055|   3.0816E8|1986-03-14|            308.16|\n",
      "|  MSFT|   0.10069445|   0.10243055| 0.07465584|  0.10069445|   0.10329861| 1.331712E8|1986-03-17|          133.1712|\n",
      "|  MSFT|   0.10243055|   0.09982639|0.072757795| 0.098958336|   0.10329861|  6.77664E7|1986-03-18|           67.7664|\n",
      "|  MSFT|   0.09982639|  0.098090276|0.071492456| 0.097222224|   0.10069445|  4.78944E7|1986-03-19|           47.8944|\n",
      "|  MSFT|  0.098090276|   0.09548611|  0.0695944|  0.09461805|  0.098090276|  5.84352E7|1986-03-20|           58.4352|\n",
      "|  MSFT|   0.09548611|   0.09288195| 0.06769639| 0.091145836|  0.097222224|  5.99904E7|1986-03-21|           59.9904|\n",
      "|  MSFT|   0.09288195|  0.090277776|0.065798335| 0.089409724|   0.09288195|  6.52896E7|1986-03-24|           65.2896|\n",
      "|  MSFT|  0.090277776|   0.09201389|  0.0670637| 0.089409724|   0.09201389|  3.20832E7|1986-03-25|           32.0832|\n",
      "|  MSFT|   0.09201389|   0.09461805| 0.06896174| 0.091145836|   0.09548611|   2.2752E7|1986-03-26|            22.752|\n",
      "|  MSFT|   0.09461805|  0.096354164|0.070227094|  0.09461805|  0.096354164|   1.6848E7|1986-03-27|            16.848|\n",
      "|  MSFT|  0.096354164|   0.09548611|  0.0695944|     0.09375|  0.096354164|  1.28736E7|1986-03-31|           12.8736|\n",
      "|  MSFT|   0.09548611|   0.09461805| 0.06896174|  0.09461805|   0.09548611|   1.1088E7|1986-04-01|            11.088|\n",
      "|  MSFT|   0.09461805|   0.09548611|  0.0695944|  0.09461805|  0.097222224|  2.70144E7|1986-04-02|           27.0144|\n",
      "|  MSFT|  0.096354164|  0.096354164|0.070227094| 0.096354164|  0.098958336|    2.304E7|1986-04-03|             23.04|\n",
      "|  MSFT|  0.096354164|  0.096354164|0.070227094| 0.096354164|  0.097222224|  2.65824E7|1986-04-04|           26.5824|\n",
      "|  MSFT|  0.096354164|   0.09461805| 0.06896174|  0.09288195|  0.097222224|    1.656E7|1986-04-07|             16.56|\n",
      "|  MSFT|   0.09461805|   0.09548611|  0.0695944|  0.09461805|  0.097222224|  1.02528E7|1986-04-08|           10.2528|\n",
      "|  MSFT|   0.09548611|  0.097222224| 0.07085974|  0.09548611|  0.098090276|  1.21536E7|1986-04-09|           12.1536|\n",
      "|  MSFT|  0.097222224|  0.098090276|0.071492456|  0.09548611|  0.098958336|  1.38816E7|1986-04-10|           13.8816|\n",
      "+------+-------------+-------------+-----------+------------+-------------+-----------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = spark.sql(\"SELECT * FROM stocks WHERE symbol='MSFT'\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_url = \"0.0.0.0:5432\"\n",
    "\n",
    "\n",
    "data_frame.write.format(\"jdbc\").options(\n",
    "    url= \"jdbc:\" + database_url,\n",
    "    driver='org.postgresql.Driver',\n",
    "     dbtable='pyspark_user',\n",
    "      user='postgres',\n",
    "      password='').mode('append').save()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
